<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Oli Pratt</title><link href="http://olipratt.co.uk/" rel="alternate"></link><link href="http://olipratt.co.uk/feeds/all.atom.xml" rel="self"></link><id>http://olipratt.co.uk/</id><updated>2018-02-25T12:27:00+00:00</updated><entry><title>Rebuilding Makefile Targets Only When Dependency Content Changes</title><link href="http://olipratt.co.uk/rebuilding-makefile-targets-only-when-dependency-content-changes.html" rel="alternate"></link><published>2018-02-25T12:27:00+00:00</published><updated>2018-02-25T12:27:00+00:00</updated><author><name>Oli Pratt</name></author><id>tag:olipratt.co.uk,2018-02-25:/rebuilding-makefile-targets-only-when-dependency-content-changes.html</id><summary type="html">&lt;h4 id="tldr"&gt;TL;DR:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GNU Make decides whether to rebuild a &amp;lsquo;target&amp;rsquo; file based on the modification times of &amp;lsquo;dependency&amp;rsquo; files of the target.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In some cases those dependencies&amp;rsquo; modification times can change &lt;em&gt;without&lt;/em&gt; the contents of the files changing, thus forcing an unnecessary rebuild.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If &lt;code&gt;make&lt;/code&gt; was to decide whether to rebuild by looking at the hash of the contents of the dependency files instead, it would only rebuild when the contents changed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I wrote a â€¦&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;h4 id="tldr"&gt;TL;DR:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GNU Make decides whether to rebuild a &amp;lsquo;target&amp;rsquo; file based on the modification times of &amp;lsquo;dependency&amp;rsquo; files of the target.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In some cases those dependencies&amp;rsquo; modification times can change &lt;em&gt;without&lt;/em&gt; the contents of the files changing, thus forcing an unnecessary rebuild.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If &lt;code&gt;make&lt;/code&gt; was to decide whether to rebuild by looking at the hash of the contents of the dependency files instead, it would only rebuild when the contents changed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I wrote a utility for doing this as a simple makefile to include, and it is on Github here: &lt;a href="https://github.com/olipratt/hashdeps"&gt;hashdeps&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;p&gt;A common thing I do when working in a Git repo is switch branches to play about with something on a separate branch, then swap back to the main branch I was working on.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://stackoverflow.com/questions/2179722/checking-out-old-file-with-original-create-modified-timestamps/2179825#2179825"&gt;Git does not store modification times&lt;/a&gt;. When Git changes a file &amp;ndash; say in the above case to replace the copy in the original branch with the version from the new branch, then again to replace it with its original contents on the first branch &amp;ndash; it updates the modification time of the file to be the current time, i.e. the same as if I&amp;rsquo;d just written the file myself.&lt;/p&gt;
&lt;p&gt;Now when you run a &lt;code&gt;make&lt;/code&gt; command on this repo, make thinks all these files are newly modified, so all the targets that depend on them need rebuilding &amp;ndash; even if the file content is the same as the last time it built.&lt;/p&gt;
&lt;p&gt;Wouldn&amp;rsquo;t it be better if &lt;code&gt;make&lt;/code&gt; instead could tell that the dependency files used to build a target hadn&amp;rsquo;t actually changed, so didn&amp;rsquo;t rebuild anything?&lt;/p&gt;
&lt;h2 id="does-this-already-exist"&gt;Does this Already Exist?&lt;/h2&gt;
&lt;p&gt;From various searching online I couldn&amp;rsquo;t find any standard solution to this problem. A fair few Stack Overflow answers amounted to &amp;lsquo;use &lt;a href="http://scons.org/"&gt;Scons&lt;/a&gt; instead&amp;rsquo;, which seems to support looking at files hashes natively. But I like make and have used it extensively already, and don&amp;rsquo;t want to add more dependencies to small projects &amp;ndash; a big advantage of GNU Make is that it&amp;rsquo;s basically always available.&lt;/p&gt;
&lt;p&gt;After a bit more searching, I did find a &lt;a href="https://www.cmcrossroads.com/article/rebuilding-when-files-checksum-changes"&gt;12 year old article&lt;/a&gt; which outlines a hack to use file hashes, but in the opposite way to my main use case &amp;ndash; forcing a rebuild if the contents of a file change, but the modification time of the file is still older than the target.&lt;/p&gt;
&lt;p&gt;From this though I thought I could probably take a stab at adapting this to my use case, and hopefully implement something sufficiently generic that this doesn&amp;rsquo;t have to be solved again.&lt;/p&gt;
&lt;h2 id="attempting-an-implementation"&gt;Attempting an Implementation&lt;/h2&gt;
&lt;p&gt;I was ready to start giving this a try. Following the article above, creating a file containing the hash of a dependency and inserting it as a dependency in between the target and dependency &amp;ndash; i.e. replace the dependency chain &lt;code&gt;a &amp;lt;- b&lt;/code&gt; with &lt;code&gt;a &amp;lt;- hashfile &amp;lt;- b&lt;/code&gt; &amp;ndash; seems like a solid start.&lt;/p&gt;
&lt;h3 id="testing"&gt;Testing&lt;/h3&gt;
&lt;p&gt;First though, I wanted to be sure I could test anything I made worked. My default would be to go for writing tests in Python, but given this was going to be just running &lt;code&gt;make&lt;/code&gt; and looking at files, it felt overkill, so I looked around for shell-based test frameworks.&lt;/p&gt;
&lt;p&gt;I found two main ones:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/kward/shunit2"&gt;shunit2&lt;/a&gt; - inactive for several years, but with a recent burst of activity.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/sstephenson/bats"&gt;bats&lt;/a&gt; - inactive for a few years now. Introduced me to &lt;a href="http://testanything.org/"&gt;TAP&lt;/a&gt; which was something I&amp;rsquo;d never heard of before, but as far as I can tell it never took off.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The big swinger here for me was that &lt;code&gt;shunit2&lt;/code&gt; is actually packaged up &amp;ndash; &lt;code&gt;apt-get install shunit2&lt;/code&gt; &amp;lsquo;just works&amp;rsquo; &amp;ndash; plus the interface matches the &lt;code&gt;junit&lt;/code&gt; style of test writing I&amp;rsquo;m familiar with from Python&amp;rsquo;s &lt;code&gt;unittest&lt;/code&gt;, so I went with that.&lt;/p&gt;
&lt;p&gt;So now we have a &lt;a href="https://github.com/olipratt/hashdeps/commit/cb83540cce7304f4b660d23786af41910a9c8582"&gt;first commit of a failing test&lt;/a&gt; &amp;ndash; time to get to work!&lt;/p&gt;
&lt;h3 id="better-understanding-of-make"&gt;Better Understanding of Make&lt;/h3&gt;
&lt;p&gt;I was very keen to have a simple interface for this utility - in particular, I wanted to be able to add this to any existing makefile by tweaking it as little as possible (i.e. not rewriting all rules with some custom logic for each one), and, if it was going to mean having to change the internals of other makefiles,  then be able to seamlessly enable/disable it from doing anything easily.&lt;/p&gt;
&lt;p&gt;I still couldn&amp;rsquo;t quite see how this was going to work though, because my understanding was that make:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;first reads all the make files to build up the hierarchy of dependencies, then&lt;/li&gt;
&lt;li&gt;works out what things need rebuilding &amp;ndash; i.e. in the hierarchy &lt;code&gt;a &amp;lt;- b &amp;lt;- c&lt;/code&gt;, touching &lt;code&gt;c&lt;/code&gt; means make decides &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; need rebuilding, so queues up jobs to build each of those,&lt;/li&gt;
&lt;li&gt;finally starts running all the jobs, parallelising any if possible.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, the second point above is wrong. After running several jobs with &lt;code&gt;--debug=a&lt;/code&gt; passed to &lt;code&gt;make&lt;/code&gt; to get lots of detailed logs out, I worked out that make actually builds a dependency of a target and &lt;em&gt;only then&lt;/em&gt; compares the timestamp of the dependency and target. So if you don&amp;rsquo;t touch the dependency (i.e. in our case, check that the hash in the file matches so don&amp;rsquo;t touch it), then make will look at the target, decide &amp;lsquo;oh this is already newer so nothing to do here!&amp;rsquo; and move on.&lt;/p&gt;
&lt;p&gt;With this I could build a working utility for my use case.&lt;/p&gt;
&lt;h3 id="supporting-more-use-cases"&gt;Supporting More Use Cases&lt;/h3&gt;
&lt;p&gt;Now that I had my use-case working, it made sense to also add in support for the case from the old article above &amp;ndash; forcing regenerating the hash each time to handle the dependency having changed but still having an older modification time than the target. I added that behaviour, controlled by a configuration flag - &lt;code&gt;HASHDEPS_FORCE&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;That still left some undesirable behaviour &amp;ndash; in the case where the dependency isn&amp;rsquo;t changed, but somehow the hash file is newer than the target, then we still rebuild the target. Since make is still in control of deciding what to build, and the hierarchy of dependencies is &lt;code&gt;a &amp;lt;- hashfile &amp;lt;- b&lt;/code&gt;, a newer &lt;code&gt;hashfile&lt;/code&gt; forces rebuilding of &lt;code&gt;a&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now using our knowledge of how make decides if it needs to rebuild a target, what if we push the modification time of the hash file &lt;em&gt;back in time&lt;/em&gt; so it&amp;rsquo;s definitely older than the target? It turns out that does work &amp;ndash; so by setting the modification time of the hashfile back say 5 years if the hash it contains still matches the hash of the dependency, we can be confident that the target won&amp;rsquo;t be rebuilt!&lt;/p&gt;
&lt;p&gt;To best see how all cases are handled, &lt;a href="https://github.com/olipratt/hashdeps/blob/master/tests/test_mod_time_combinations.sh"&gt;the table in this Unit Test file&lt;/a&gt; covers all the cases, and the tests below it check that they really are handled as described.&lt;/p&gt;
&lt;p&gt;In particular notice that now the &amp;lsquo;force&amp;rsquo; case rebuilds the target &amp;lsquo;if-and-only-if&amp;rsquo; the dependency file has actually changed &amp;ndash; so it always does the right thing, at the cost of having to always recalculate the hash every build.&lt;/p&gt;
&lt;h2 id="result"&gt;Result&lt;/h2&gt;
&lt;p&gt;The output of all this is that there&amp;rsquo;s now a makefile available that can be included in any other makefile-based build system to add this dependency hashing functionality.&lt;/p&gt;
&lt;p&gt;Here it is: &lt;a href="https://github.com/olipratt/hashdeps"&gt;hashdeps&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/olipratt/hashdeps#converting-a-target-to-use-hashed-dependencies"&gt;The API&lt;/a&gt; is as clean as I could make it &amp;ndash; you just wrap any dependency names in a make function call &lt;code&gt;hash_deps&lt;/code&gt;, and wrap any uses of built in make variables referencing dependencies in &lt;code&gt;unhash_deps&lt;/code&gt;. &lt;em&gt;(It does mean that you have to edit any targets you want to use this, but something like that would be necessary anyway unless it was going to apply to all targets blindly.)&lt;/em&gt; Also, just setting the make variable &lt;code&gt;HASHDEPS_DISABLE=y&lt;/code&gt; disables any hashing function, so your makefiles behave exactly as if &lt;code&gt;hashdeps&lt;/code&gt; wasn&amp;rsquo;t even there.&lt;/p&gt;</content><category term="GNU Make"></category><category term="builds"></category></entry><entry><title>Building VS Code Extensions in Docker Containers</title><link href="http://olipratt.co.uk/building-vs-code-extensions-in-docker-containers.html" rel="alternate"></link><published>2018-02-23T19:52:00+00:00</published><updated>2018-02-23T19:52:00+00:00</updated><author><name>Oli Pratt</name></author><id>tag:olipratt.co.uk,2018-02-23:/building-vs-code-extensions-in-docker-containers.html</id><summary type="html">&lt;h4 id="tldr"&gt;TL;DR:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://code.visualstudio.com/"&gt;VS Code&lt;/a&gt; is an editor that allows you to &lt;a href="https://code.visualstudio.com/docs/extensions/example-hello-world"&gt;write&lt;/a&gt; and &lt;a href="https://marketplace.visualstudio.com/"&gt;share&lt;/a&gt; custom extensions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;These extensions require &lt;code&gt;Node.js&lt;/code&gt; and &lt;code&gt;npm&lt;/code&gt; installed, which you might not want to install locally - especially &lt;a href="https://www.bleepingcomputer.com/news/linux/botched-npm-update-crashes-linux-systems-forces-users-to-reinstall/"&gt;given recent, scary issues&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Instead, using the &lt;code&gt;Dockerfile&lt;/code&gt; and commands below, you can build extensions inside a Docker container and still test and run them inside the VS Code installation on the same machine without Node installed.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;ve been using â€¦&lt;/p&gt;</summary><content type="html">&lt;h4 id="tldr"&gt;TL;DR:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://code.visualstudio.com/"&gt;VS Code&lt;/a&gt; is an editor that allows you to &lt;a href="https://code.visualstudio.com/docs/extensions/example-hello-world"&gt;write&lt;/a&gt; and &lt;a href="https://marketplace.visualstudio.com/"&gt;share&lt;/a&gt; custom extensions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;These extensions require &lt;code&gt;Node.js&lt;/code&gt; and &lt;code&gt;npm&lt;/code&gt; installed, which you might not want to install locally - especially &lt;a href="https://www.bleepingcomputer.com/news/linux/botched-npm-update-crashes-linux-systems-forces-users-to-reinstall/"&gt;given recent, scary issues&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Instead, using the &lt;code&gt;Dockerfile&lt;/code&gt; and commands below, you can build extensions inside a Docker container and still test and run them inside the VS Code installation on the same machine without Node installed.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;ve been using VS Code as my main editor for personal work for some time now, but only just got around to trying to create an extension.&lt;/p&gt;
&lt;p&gt;I don&amp;rsquo;t do any Node or Javascript development normally, so don&amp;rsquo;t have Node/NPM installed, and &lt;a href="https://code.visualstudio.com/docs/extensions/example-hello-world"&gt;that&amp;rsquo;s the first thing the docs tell you to do&lt;/a&gt;.
Keen not to install these on my system given the bloat I&amp;rsquo;ve heard they add and &lt;a href="https://www.bleepingcomputer.com/news/linux/botched-npm-update-crashes-linux-systems-forces-users-to-reinstall/"&gt;recent issues&lt;/a&gt;, I wanted to do try and do the necessary generation and building in a container.&lt;/p&gt;
&lt;p&gt;Searching online for various combinations of relevant keywords only seemed to give me articles on writing extensions to work with Docker files/containers, and I had to poke about and get this working myself. I thought I&amp;rsquo;d write up how I did it in case it&amp;rsquo;s useful for someone else.&lt;/p&gt;
&lt;h2 id="getting-started"&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;Obviously you&amp;rsquo;ll need docker installed and set up.&lt;/p&gt;
&lt;p&gt;Then the following &lt;code&gt;Dockerfile&lt;/code&gt; will allow you to create a container with the VS Code extension generator ready and installed.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="s"&gt; node:latest&lt;/span&gt;

&lt;span class="k"&gt;RUN&lt;/span&gt; npm install -g yo generator-code

USER node
&lt;span class="k"&gt;WORKDIR&lt;/span&gt;&lt;span class="s"&gt; /home/node/&lt;/span&gt;

&lt;span class="k"&gt;ENTRYPOINT&lt;/span&gt;&lt;span class="s"&gt; bash&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Create a copy of that &lt;code&gt;Dockerfile&lt;/code&gt; and build it - I called it &lt;code&gt;vscodeextenv&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo docker build -t vscodeextenv .
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now I created a directory ready and named for my extension, and mounted that into the container.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mkdir example
sudo docker run -it &lt;span class="se"&gt;\&lt;/span&gt;
     --mount &lt;span class="nv"&gt;source&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;/example,target&lt;span class="o"&gt;=&lt;/span&gt;/home/node/example,type&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;bind&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
     vscodeextenv
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now you should have an environment ready to build an extension.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Gotcha:&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;I found out that &lt;a href="https://docs.docker.com/storage/volumes/"&gt;docker now recommends&lt;/a&gt; you use &lt;code&gt;--mount&lt;/code&gt; to mount directories inside a container rather than &lt;code&gt;-v&lt;/code&gt;, but using that ended up with the mounted directory inside the container being owned by root until I added &lt;code&gt;type=bind&lt;/code&gt; to the &lt;code&gt;mount&lt;/code&gt; option.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="building-the-extension"&gt;Building the Extension&lt;/h2&gt;
&lt;p&gt;Here you can just run the extension generator with &lt;code&gt;yo code&lt;/code&gt; and follow the prompts. I named mine example, and just used dummy values for everything else. Like a good developer I also turned on all the linting ðŸ˜‰.&lt;/p&gt;
&lt;p&gt;Once it&amp;rsquo;s generated, &lt;a href="https://code.visualstudio.com/docs/extensions/example-hello-world#_running-your-extension"&gt;the docs&lt;/a&gt; say to start debugging the extension, but from what I can tell that first builds the extension, which won&amp;rsquo;t work since we don&amp;rsquo;t have all the dependencies installed. If I try, I get a few errors/stack traces in the debug console and this notification in the original VS Code instance&lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Text" src="/static/images/vscode_extension_debug_error.png"&gt;&lt;/p&gt;
&lt;p&gt;The second instance that&amp;rsquo;s supposed to have the extension loaded does open, but doesn&amp;rsquo;t have it loaded in.&lt;/p&gt;
&lt;p&gt;So we need to build it manually first.&lt;/p&gt;
&lt;p&gt;This might be obvious if you&amp;rsquo;re a proficient &lt;code&gt;node&lt;/code&gt; developer, but after some poking through the generated files I found the command - in the container, run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;npm run compile
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You&amp;rsquo;ll now have an &lt;code&gt;out&lt;/code&gt; directory, which is what VS Code needs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Gotcha:&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;For me the &lt;code&gt;compile&lt;/code&gt; command failed with an error I think because I enabled the various linting and strict options when generating the project - this is fixed for now by commenting these lines out in &lt;code&gt;src/test/extension.test.ts&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;// import * as vscode from &amp;#39;vscode&amp;#39;;&lt;/span&gt;
&lt;span class="c1"&gt;// import * as myExtension from &amp;#39;../extension&amp;#39;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="testing-the-extension-in-vs-code"&gt;Testing the extension in VS Code&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Now&lt;/em&gt; you should be able to, in VS Code, just open the &lt;code&gt;Debug&lt;/code&gt; tab and press the &lt;code&gt;Play&lt;/code&gt; button, and the new instance of VS Code with your app loaded should appear!&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;ve just used the default app, then &lt;code&gt;Ctrl+Shift+P&lt;/code&gt; in the new instance should allow you to find the &lt;code&gt;hello world&lt;/code&gt; command, and running it should correctly show the notification.&lt;/p&gt;
&lt;p&gt;The only downsides are that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the original VS Code instance still shows the error in the image above (I think because it still tries to build the extension and fails), though it runs fine regardless,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;you have to remember to manually build the extension in the container before running it in the VS Code debugger.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><category term="VS Code"></category><category term="Docker"></category></entry><entry><title>Docker Container for a simple Flask App</title><link href="http://olipratt.co.uk/docker-container-for-a-simple-flask-app.html" rel="alternate"></link><published>2017-03-01T21:36:00+00:00</published><updated>2017-03-01T21:36:00+00:00</updated><author><name>Oli Pratt</name></author><id>tag:olipratt.co.uk,2017-03-01:/docker-container-for-a-simple-flask-app.html</id><summary type="html">&lt;p&gt;Continuing the recent microservices trend, I tried to containerise a previous project, a small REST datastore - &lt;a href="http://olipratt.co.uk/python-rest-api-with-swaggerui.html"&gt;microstore&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m not going to go into detail on what containers are (not least because I don&amp;rsquo;t think I could!) - but briefly they are a way to package up an app and it&amp;rsquo;s dependencies so they can be run in their own mini-environment. The best intro is just to follow the tutorial &lt;a href="https://docs.docker.com/engine/getstarted/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="creating-the-container"&gt;Creating the Container â€¦&lt;/h2&gt;</summary><content type="html">&lt;p&gt;Continuing the recent microservices trend, I tried to containerise a previous project, a small REST datastore - &lt;a href="http://olipratt.co.uk/python-rest-api-with-swaggerui.html"&gt;microstore&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m not going to go into detail on what containers are (not least because I don&amp;rsquo;t think I could!) - but briefly they are a way to package up an app and it&amp;rsquo;s dependencies so they can be run in their own mini-environment. The best intro is just to follow the tutorial &lt;a href="https://docs.docker.com/engine/getstarted/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="creating-the-container"&gt;Creating the Container&lt;/h2&gt;
&lt;p&gt;I installed &lt;a href="https://docs.docker.com/engine/installation/linux/centos/"&gt;Docker on CentOS&lt;/a&gt;. It warns you not to just &lt;code&gt;yum install&lt;/code&gt;, so instead I followed the &lt;em&gt;Install from a package&lt;/em&gt; instructions - but note that you now have to always run docker commands with &lt;code&gt;sudo&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Containerising an app was simple - basically &lt;a href="https://runnable.com/docker/python/dockerize-your-flask-application"&gt;just follow this tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/olipratt/microstore/blob/master/Dockerfile"&gt;Here&amp;rsquo;s&lt;/a&gt; the &lt;code&gt;Dockerfile&lt;/code&gt; I created following that - now in the microstore repo.&lt;/p&gt;
&lt;p&gt;Note I had to set the app to listen on &lt;code&gt;0.0.0.0&lt;/code&gt; because we are going to forward ports to outside the container, so need to listen on a public address inside the container.&lt;/p&gt;
&lt;p&gt;So if you have docker installed, just:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;get a clone of the microstore repo,&lt;/li&gt;
&lt;li&gt;build the container image with: &lt;code&gt;sudo docker build -t microstore:latest .&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;then run it with: &lt;code&gt;sudo docker run -p 5000:5000 microstore&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;-p 5000:5000&lt;/code&gt; binds port 5000 of the container to port 5000 on the host.
So now you can just go to &lt;code&gt;http://127.0.0.1:5000/&lt;/code&gt; in your web browser and you should see the SwaggerUI running!&lt;/p&gt;
&lt;p&gt;Some notes on running containers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If there&amp;rsquo;s a problem building/running the app, you can just run the same commands again after fixing the problem.&lt;/li&gt;
&lt;li&gt;Add the &lt;code&gt;-d&lt;/code&gt; option to run the container in the background.&lt;/li&gt;
&lt;li&gt;Note &lt;code&gt;sudo docker ps&lt;/code&gt; shows what containerised apps are running.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="shipping-an-image"&gt;Shipping an Image&lt;/h2&gt;
&lt;p&gt;You can now create the final container ready to ship with &lt;code&gt;sudo docker save microstore &amp;gt; microstore.tar&lt;/code&gt;. This one was about 300MB when I created it.&lt;/p&gt;
&lt;p&gt;Later/elsewhere you can reload it with &lt;code&gt;sudo docker load &amp;lt; microstore.tar&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="composing-multiple-containers"&gt;Composing Multiple Containers&lt;/h2&gt;
&lt;p&gt;Now I&amp;rsquo;d got one running, I wanted to see how you&amp;rsquo;d ship several microservices given they would need to contact each other over IP somehow. Turns out that&amp;rsquo;s simple too using &lt;code&gt;docker-compose&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Again, not going into detail on this as it&amp;rsquo;s all online.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There&amp;rsquo;s a good tutorial &lt;a href="https://docs.docker.com/compose/gettingstarted/"&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;You may need to specify a &lt;a href="https://docs.docker.com/compose/startup-order/"&gt;startup order&lt;/a&gt; so that a service is created before another tries to connect to it.&lt;/li&gt;
&lt;li&gt;Networking between services is also simple - basically &lt;a href="https://docs.docker.com/compose/networking/"&gt;access the name of a service in the compose file as a hostname&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I set up my little card deck service with a &lt;a href="https://github.com/olipratt/microcarddeck/blob/master/Dockerfile"&gt;Dockerfile&lt;/a&gt; and &lt;a href="https://github.com/olipratt/microcarddeck/blob/master/docker-compose.yml"&gt;compose file&lt;/a&gt; to run it and the microstore together. If you built the microstore container above, then by just running &lt;code&gt;sudo docker-compose up&lt;/code&gt; in the card deck repo it will build the second image and then run them both together - magic!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;One note - I was confused that &lt;code&gt;sudo docker-compose up&lt;/code&gt; didn&amp;rsquo;t rebuild the image after fixing a bug in the &lt;code&gt;Dockerfile&lt;/code&gt; but, as per &lt;a href="https://github.com/docker/compose/issues/1487"&gt;here&lt;/a&gt;, you need to run &lt;code&gt;sudo docker-compose build&lt;/code&gt; to force it to rebuild - &lt;code&gt;up&lt;/code&gt; won&amp;rsquo;t ever rebuild.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="tidying-up"&gt;Tidying up&lt;/h2&gt;
&lt;p&gt;Docker seems to leave images that you create as you iterate lying around, and you have to do a bit of manual cleanup at the end. As noted in &lt;a href="https://docs.docker.com/compose/gettingstarted/"&gt;here&lt;/a&gt; you can clear up composed containers with &lt;code&gt;sudo docker-compose down&lt;/code&gt;. You can then &lt;a href="https://docs.docker.com/engine/reference/commandline/image_prune/"&gt;prune&lt;/a&gt; and &lt;a href="https://docs.docker.com/engine/reference/commandline/rm/#/remove-all-stopped-containers"&gt;remove unused images&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;That was really simple and Docker seems like a great way for running at least simple apps in a controlled environment. What&amp;rsquo;s been your experience with Docker, if any?&lt;/p&gt;</content><category term="Python"></category><category term="Flask"></category><category term="Container"></category><category term="Docker"></category><category term="microservice"></category></entry><entry><title>Python Microservice Logging</title><link href="http://olipratt.co.uk/python-microservice-logging.html" rel="alternate"></link><published>2017-02-25T14:39:00+00:00</published><updated>2017-02-25T14:39:00+00:00</updated><author><name>Oli Pratt</name></author><id>tag:olipratt.co.uk,2017-02-25:/python-microservice-logging.html</id><summary type="html">&lt;p&gt;After looking into &lt;a href="http://olipratt.co.uk/python-rest-api-with-swaggerui.html"&gt;microservices&lt;/a&gt; &lt;a href="http://olipratt.co.uk/python-rest-api-client-adhering-to-a-swagger-schema.html"&gt;recently&lt;/a&gt;, I was running multiple terminals and switching between them to look at logs as they are written to screen. This was a little awkward so I thought it was worth looking for the right way to log to a central location from multiple microservices. Ideally I wanted do this just using the Python logging library, and without adding more dependencies to every service.&lt;/p&gt;
&lt;p&gt;This meant a lot of reading around â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;After looking into &lt;a href="http://olipratt.co.uk/python-rest-api-with-swaggerui.html"&gt;microservices&lt;/a&gt; &lt;a href="http://olipratt.co.uk/python-rest-api-client-adhering-to-a-swagger-schema.html"&gt;recently&lt;/a&gt;, I was running multiple terminals and switching between them to look at logs as they are written to screen. This was a little awkward so I thought it was worth looking for the right way to log to a central location from multiple microservices. Ideally I wanted do this just using the Python logging library, and without adding more dependencies to every service.&lt;/p&gt;
&lt;p&gt;This meant a lot of reading around to reach a rather boring and obvious solution. I documented my whistle-stop tour around the world of logging, but jump to the end to just see the &lt;a href="#real-solution"&gt;solution&lt;/a&gt; I went with.&lt;/p&gt;
&lt;h2 id="picking-a-format"&gt;Picking a format&lt;/h2&gt;
&lt;h4 id="open-standards"&gt;Open Standards&lt;/h4&gt;
&lt;p&gt;Straight off - there&amp;rsquo;s no obvious standardised server package for receiving logs over the network from the Python logging module. I initially thought this whole thing would just take a 5 minute search - maybe this should have been a clue.&lt;/p&gt;
&lt;p&gt;So I started looking around for other open logging formats and log stores. Turns out there&amp;rsquo;s quite a few of these.  &lt;a href="http://docs.graylog.org/en/2.2/pages/gelf.html"&gt;GELF&lt;/a&gt; seemed like maybe a good option. It&amp;rsquo;s open, JSON structured format, integrates with many log stores, and has a &lt;a href="https://github.com/severb/graypy"&gt;Python logging module handler&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://docs.graylog.org/en/2.2/pages/installation.html"&gt;The GELF server&lt;/a&gt; is pretty massive though - delivered as a whole VM, ideally I just wanted a simple listener script I could run. I did find a &lt;a href="http://idlethreat.com/blog/graylog/gelf-listener-in-python/"&gt;single simple server implementation&lt;/a&gt;, but that was it. I got it all running easily enough, and though I could have tidied it up and used it, I felt I was off the beaten path and had added a new dependency to every service for logging so kept digging for a bit.&lt;/p&gt;
&lt;h4 id="too-cumbersome-back-to-simple-http"&gt;Too Cumbersome - Back to Simple HTTP&lt;/h4&gt;
&lt;p&gt;Going back to the logging module, it looked like basic &lt;a href="https://docs.python.org/3/library/logging.handlers.html#httphandler"&gt;HTTPHandler&lt;/a&gt; would do, and meant no dependencies. However, I found &lt;a href="http://ericshtiv.blogspot.co.uk/2012/12/python-fast-http-logging-handler.html"&gt;warnings that it was slow&lt;/a&gt;, but then a &lt;a href="http://plumberjack.blogspot.co.uk/2010/09/improved-queuehandler-queuelistener.html"&gt;solution&lt;/a&gt; to that using the logging module&amp;rsquo;s &lt;a href="https://docs.python.org/3.6/library/logging.handlers.html#queuehandler"&gt;queuehandler&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I got that working, but the POST body from the HTTPHandler was not JSON but just a &lt;a href="http://stackoverflow.com/a/14551320"&gt;URL encoded string&lt;/a&gt;. I could easily decode this in a Flask server, but then it was still a lot of code to copy paste and I might as well just shove in a JSON body instead. So I reworked that into a REST log handler - which I still have lying around:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;configure_remote_logging&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;client_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;INFO&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Set up remote logging to the specified url.&lt;/span&gt;

&lt;span class="sd"&gt;    This sets up a queue which logs are placed onto, and then they are sent on&lt;/span&gt;
&lt;span class="sd"&gt;    a background thread so they don&amp;#39;t slow down the code making the logs.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="c1"&gt;# The handler which will send logs remotely - definition and an instance.&lt;/span&gt;
    &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;RESTHandler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Handler&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Handler which sends logs to a REST log server.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

        &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;client_name&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;RESTHandler&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;
            &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;client_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;client_name&lt;/span&gt;

        &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;log_record&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;formatted&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;log_record&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="vm"&gt;__dict__&lt;/span&gt;
            &lt;span class="n"&gt;formatted&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;processName&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;client_name&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;formatted&lt;/span&gt;

        &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;emit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;log_record&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
            &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;post&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;log_record&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="n"&gt;rest_handler&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RESTHandler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;client_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;rest_handler&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setLevel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Create queue handlers so that logs are processed in a background thread.&lt;/span&gt;
    &lt;span class="c1"&gt;# Set up an unbounded size queue and assume logs are processed faster than&lt;/span&gt;
    &lt;span class="c1"&gt;# they are made.&lt;/span&gt;
    &lt;span class="n"&gt;logging_queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Queue&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;queue_handler&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;handlers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QueueHandler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logging_queue&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;queue_listener&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;handlers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QueueListener&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logging_queue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                    &lt;span class="n"&gt;rest_handler&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Add the remote logging handler and start the background queue running.&lt;/span&gt;
    &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getLogger&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;addHandler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;queue_handler&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;queue_listener&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# Should call this on exit to ensure all final logs are flushed.&lt;/span&gt;
    &lt;span class="c1"&gt;# queue_listener.stop()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then receiving the log is simple on the Flask server side - just:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;LogsCollection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Resource&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;post&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Receives a log.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;makeLogRecord&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_json&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;201&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But now:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I should really be calling the commented out &lt;code&gt;stop&lt;/code&gt; method on the queue when the app exits, otherwise logs can end up not being flushed - which means some kind of global state to store a reference to that queue and a hook to call it.&lt;/li&gt;
&lt;li&gt;The overhead of a HTTP POST for every log seems high - especially at the debug level.&lt;/li&gt;
&lt;li&gt;I&amp;rsquo;ve still got a huge block of code to copy/paste into every service, or otherwise write a package and add another dependency.&lt;/li&gt;
&lt;li&gt;I&amp;rsquo;ve added a dependency on &lt;code&gt;requests&lt;/code&gt; in there.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sigh.&lt;/p&gt;
&lt;h4 id="no-no-lets-use-a-standard"&gt;No, No - Let&amp;rsquo;s Use a Standard&lt;/h4&gt;
&lt;p&gt;Clearly that&amp;rsquo;s the wrong approach - throw it away and start over. Really we should be going with a standard so we can integrate with other things, and that ended up with me looking into syslog since&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it seemed frequently &lt;a href="http://www.structlog.org/en/stable/logging-best-practices.html#syslog-again"&gt;recommended&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;well used and supported by every client/server,&lt;/li&gt;
&lt;li&gt;has a built in &lt;a href="https://docs.python.org/3/library/logging.handlers.html#sysloghandler"&gt;Python logging handler&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;I &lt;a href="https://gist.github.com/marcelom/4218010"&gt;found a tiny Python listener for it&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;and &lt;a href="https://tools.ietf.org/html/rfc5424"&gt;it&amp;rsquo;s so standardised it has an RFC&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This &lt;em&gt;had&lt;/em&gt; to be the right answer, so I wrote some client code for that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;configure_logging&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;client_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;INFO&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Set up logging to stderr and optionally a remote syslog server.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;handlers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;host&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;syslog_fmt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;1 &lt;/span&gt;&lt;span class="si"&gt;%(asctime)s&lt;/span&gt;&lt;span class="s1"&gt;.&lt;/span&gt;&lt;span class="si"&gt;%(msecs)03d&lt;/span&gt;&lt;span class="s1"&gt;Z {} {} - - - &amp;#39;&lt;/span&gt;
                      &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;%(message)s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;socket&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getfqdn&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;client_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;syslog_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;%Y-%m-&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt;T%H:%M:%S&amp;#39;&lt;/span&gt;
        &lt;span class="n"&gt;syslog_formatter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Formatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;syslog_fmt&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;datefmt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;syslog_date&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# Force UTC time so we can just stick `Z` at the end of the timestamp.&lt;/span&gt;
        &lt;span class="n"&gt;syslog_formatter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;converter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gmtime&lt;/span&gt;

        &lt;span class="n"&gt;syslog_handler&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;handlers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SysLogHandler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;address&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;514&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;syslog_handler&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setFormatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;syslog_formatter&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;handlers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;syslog_handler&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;stderr_fmt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="si"&gt;%(asctime)-23s&lt;/span&gt;&lt;span class="s1"&gt;:&lt;/span&gt;&lt;span class="si"&gt;%(levelname)-8s&lt;/span&gt;&lt;span class="s1"&gt;:&lt;/span&gt;&lt;span class="si"&gt;%(message)s&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;stderr_formatter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Formatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stderr_fmt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;stderr_handler&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;StreamHandler&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;stderr_handler&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setFormatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stderr_formatter&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;handlers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stderr_handler&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getLogger&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setLevel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;handler&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;handlers&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;addHandler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;handler&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;em&gt;Aside: I had to build the formatter to match the RFC standard syslog format because I couldn&amp;rsquo;t easily find one elsewhere - might come in handy.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So this now works fine, it&amp;rsquo;s a reasonable chunk of code, but it&amp;rsquo;s mostly just boilerplate stuff setting up the built in logging module, and the only custom part is setting up the right formatter. All done?&lt;/p&gt;
&lt;h2 id="real-solution"&gt;Real Solution&lt;/h2&gt;
&lt;p&gt;So after all that, I think I&amp;rsquo;m done and move on to something else - containerising these apps was up next for me - &amp;hellip;and that&amp;rsquo;s when I stumble across the &lt;em&gt;right&lt;/em&gt; answer. It&amp;rsquo;s right &lt;a href="https://12factor.net/logs"&gt;here&lt;/a&gt; in these &lt;a href="https://12factor.net/"&gt;guidelines to writing services&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Just write your logs to stdout.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s it! Then whatever is running your app pipes them out and handles them appropriately. Anything else you do is just another system someone has to worry about integrating into their setup. &lt;a href="https://docs.docker.com/engine/reference/commandline/logs/#/extended-description"&gt;Docker by default assumes an app will send logs to stdout&lt;/a&gt; and handles them as configured. I saw this in action when I started using Docker - I&amp;rsquo;ll write that up soon.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;So that was an interesting bit of investigation, and I learnt some stuff, but damn if it doesn&amp;rsquo;t feel like a waste of time.&lt;/p&gt;
&lt;p&gt;How do you handle logging from your Python apps?&lt;/p&gt;</content><category term="Python"></category><category term="logging"></category><category term="syslog"></category><category term="microservice"></category></entry><entry><title>REST APIs Notes and References</title><link href="http://olipratt.co.uk/rest-apis-notes-and-references.html" rel="alternate"></link><published>2017-02-12T17:37:00+00:00</published><updated>2017-02-25T20:45:00+00:00</updated><author><name>Oli Pratt</name></author><id>tag:olipratt.co.uk,2017-02-12:/rest-apis-notes-and-references.html</id><summary type="html">&lt;p&gt;After working to create a &lt;a href="http://olipratt.co.uk/python-rest-api-with-swaggerui.html"&gt;REST API&lt;/a&gt; and &lt;a href="http://olipratt.co.uk/python-rest-api-client-adhering-to-a-swagger-schema.html"&gt;client&lt;/a&gt; recently, here are some notes and resources I found useful. I&amp;rsquo;ll keep adding to this as I find new info.&lt;/p&gt;
&lt;h4 id="general-notes"&gt;General notes&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Resource collection names should always be plural.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Depending on who (client vs server) names resources, creation switches between &lt;code&gt;PUT&lt;/code&gt;/&lt;code&gt;POST&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;client names resources:&lt;ul&gt;
&lt;li&gt;&lt;code&gt;PUT /kittens/&amp;lt;my_kittens_name&amp;gt;&lt;/code&gt; - creates a resource there&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;server names resources:&lt;ul&gt;
&lt;li&gt;&lt;code&gt;POST /things&lt;/code&gt; - Creates a new &lt;code&gt;thing&lt;/code&gt; at &lt;code&gt;/things/&amp;lt;autogened_id&amp;gt;&lt;/code&gt;, with â€¦&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;After working to create a &lt;a href="http://olipratt.co.uk/python-rest-api-with-swaggerui.html"&gt;REST API&lt;/a&gt; and &lt;a href="http://olipratt.co.uk/python-rest-api-client-adhering-to-a-swagger-schema.html"&gt;client&lt;/a&gt; recently, here are some notes and resources I found useful. I&amp;rsquo;ll keep adding to this as I find new info.&lt;/p&gt;
&lt;h4 id="general-notes"&gt;General notes&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Resource collection names should always be plural.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Depending on who (client vs server) names resources, creation switches between &lt;code&gt;PUT&lt;/code&gt;/&lt;code&gt;POST&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;client names resources:&lt;ul&gt;
&lt;li&gt;&lt;code&gt;PUT /kittens/&amp;lt;my_kittens_name&amp;gt;&lt;/code&gt; - creates a resource there&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;server names resources:&lt;ul&gt;
&lt;li&gt;&lt;code&gt;POST /things&lt;/code&gt; - Creates a new &lt;code&gt;thing&lt;/code&gt; at &lt;code&gt;/things/&amp;lt;autogened_id&amp;gt;&lt;/code&gt;, with that ID returned in the response to the post&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="some-useful-references"&gt;Some useful references&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.vinaysahni.com/best-practices-for-a-pragmatic-restful-api"&gt;General REST API best practices&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.restapitutorial.com/lessons/httpmethods.html"&gt;Explanations of the REST verbs&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;RESTful API Design Guides&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://cloud.google.com/apis/design/"&gt;Google&amp;rsquo;s&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/Microsoft/api-guidelines/blob/master/Guidelines.md"&gt;Microsoft&amp;rsquo;s&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://zalando.github.io/restful-api-guidelines/"&gt;Zalando&amp;rsquo;s&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://vimeo.com/20781278"&gt;Talk on the discoverability side of REST&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Have you got any other good general rules, notes, or references to add?&lt;/p&gt;</content><category term="REST"></category></entry><entry><title>Python REST API Client Adhering to a Swagger Schema</title><link href="http://olipratt.co.uk/python-rest-api-client-adhering-to-a-swagger-schema.html" rel="alternate"></link><published>2017-02-11T19:13:00+00:00</published><updated>2017-02-11T19:13:00+00:00</updated><author><name>Oli Pratt</name></author><id>tag:olipratt.co.uk,2017-02-11:/python-rest-api-client-adhering-to-a-swagger-schema.html</id><summary type="html">&lt;p&gt;After &lt;a href="http://olipratt.co.uk/python-rest-api-with-swaggerui.html"&gt;building a REST API&lt;/a&gt; I left it alone for a while before coming back to try and get a client working properly.&lt;/p&gt;
&lt;p&gt;Similar goals here to back then - find a good library to use going forwards that does the heavy lifting and make a simple example project. I chose a simple microservice that provides an API for decks of playing cards - like a casino dealer type of thing - which would be a client of â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;After &lt;a href="http://olipratt.co.uk/python-rest-api-with-swaggerui.html"&gt;building a REST API&lt;/a&gt; I left it alone for a while before coming back to try and get a client working properly.&lt;/p&gt;
&lt;p&gt;Similar goals here to back then - find a good library to use going forwards that does the heavy lifting and make a simple example project. I chose a simple microservice that provides an API for decks of playing cards - like a casino dealer type of thing - which would be a client of the datastore I created in the link above.&lt;/p&gt;
&lt;h2 id="choosing-a-client-package"&gt;Choosing a Client Package&lt;/h2&gt;
&lt;p&gt;The standard seems to be to &lt;a href="https://github.com/swagger-api/swagger-codegen"&gt;generate code&lt;/a&gt; to meet a schema, but I&amp;rsquo;d rather load it dynamically into an app if possible.&lt;/p&gt;
&lt;p&gt;After a bit of looking I found &lt;a href="http://bravado.readthedocs.io/en/latest/"&gt;Bravado&lt;/a&gt; which looked promising. However, it was a pain to install - it relies on the twisted package and that doesn&amp;rsquo;t seem to install on Windows through pip successfully, so after some failed attempts to get it to work I gave up. I figure it&amp;rsquo;s not worth using if it&amp;rsquo;s going to be a pain for others to install - shame :(.&lt;/p&gt;
&lt;p&gt;Next up was &lt;a href="http://pyswagger.readthedocs.io/en/latest/"&gt;pyswagger&lt;/a&gt; - it seems to provide all the functionality and be well maintained (commits in the past few days when I wrote this). The API doesn&amp;rsquo;t look as polished to me when compared to &lt;code&gt;bravado&lt;/code&gt; above, but it worked fine in practice.&lt;/p&gt;
&lt;p&gt;On the testing point - &lt;code&gt;pyswagger&lt;/code&gt; uses  &lt;code&gt;requests&lt;/code&gt; for HTTP requests, so we can easily test using the &lt;a href="https://github.com/getsentry/responses"&gt;responses&lt;/a&gt; library to provide mock responses to them.&lt;/p&gt;
&lt;h2 id="the-first-test"&gt;The First Test&lt;/h2&gt;
&lt;p&gt;This was painful to get working, but as always trivial to fix in the end.&lt;/p&gt;
&lt;p&gt;I needed to load in the schema, and then intercept the requests over the network for each API call. Intercepting the API calls was trivial with &lt;code&gt;responses&lt;/code&gt;, but loading in the schema turned out to be less so.&lt;/p&gt;
&lt;p&gt;There were two approaches I could see:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pyswagger&lt;/code&gt; lets you load in a schema from file, so just pass it a file name&lt;/li&gt;
&lt;li&gt;intercept the request for the schema over the network&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, both failed when I tried:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if I loaded in the schema from file, &lt;code&gt;pyswagger&lt;/code&gt; would then try and make API requests using the &lt;code&gt;file&lt;/code&gt; scheme, which causes it to fall over as that&amp;rsquo;s not a &lt;a href="https://github.com/mission-liao/pyswagger/blob/cff50d0b49da984666e1a350cff3e7bdf71d0b13/pyswagger/contrib/client/requests.py#L11"&gt;supported scheme&lt;/a&gt; for that part it seems.&lt;/li&gt;
&lt;li&gt;the request for the schema over the network uses &lt;a href="https://github.com/mission-liao/pyswagger/blob/cff50d0b49da984666e1a350cff3e7bdf71d0b13/pyswagger/getter.py#L136"&gt;&lt;code&gt;urllib.urlopen&lt;/code&gt; rather than &lt;code&gt;requests&lt;/code&gt;&lt;/a&gt; so I couldn&amp;rsquo;t easily intercept it with &lt;code&gt;responses&lt;/code&gt; and would have to do more mocking of the deep internals of &lt;code&gt;pyswagger&lt;/code&gt;, which seemed wrong.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lots of trial-and-error and reading of the &lt;code&gt;pyswagger&lt;/code&gt; source later I found the solution in the &lt;a href="https://github.com/mission-liao/pyswagger/blob/cff50d0b49da984666e1a350cff3e7bdf71d0b13/pyswagger/tests/contrib/client/test_requests.py#L28"&gt;tests of the client in &lt;code&gt;pyswagger&lt;/code&gt; itself&lt;/a&gt;. They were doing exactly what I was trying in the first bullet above - loading in the schema from file then intercepting API requests - so why were their API requests working? It turns out their schema had two entries not added by &lt;code&gt;Flask-RESTPlus&lt;/code&gt; - &lt;a href="https://github.com/mission-liao/pyswagger/blob/cff50d0b49da984666e1a350cff3e7bdf71d0b13/pyswagger/tests/data/v2_0/wordnik/swagger.json#L16"&gt;&lt;code&gt;host&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/mission-liao/pyswagger/blob/cff50d0b49da984666e1a350cff3e7bdf71d0b13/pyswagger/tests/data/v2_0/wordnik/swagger.json#L40"&gt;&lt;code&gt;schemes&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So I just needed this in top level of my schema saved in a file for the tests:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;quot;host&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;127.0.0.1:5000&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
   &lt;span class="nt"&gt;&amp;quot;schemes&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:[&lt;/span&gt;
      &lt;span class="s2"&gt;&amp;quot;http&amp;quot;&lt;/span&gt;
   &lt;span class="p"&gt;],&lt;/span&gt;
   &lt;span class="err"&gt;...&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;With that, &lt;code&gt;pyswagger&lt;/code&gt; can load schema from file for tests, and then send API requests over HTTP to that address, and we can use &lt;code&gt;responses&lt;/code&gt; to catch those and respond to them.&lt;/p&gt;
&lt;p&gt;Phew!&lt;/p&gt;
&lt;h2 id="overall"&gt;Overall&lt;/h2&gt;
&lt;p&gt;Once I had wasted far too long trying to get a test working, everything else was straightforward, basically just following the &lt;a href="https://github.com/mission-liao/pyswagger#tutorial"&gt;tutorials linked in the &lt;code&gt;pyswagger&lt;/code&gt; readme&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When you have loaded in the schema to &lt;code&gt;pyswagger&lt;/code&gt;, you just reference API calls by name in the schema, which &lt;code&gt;Flask-RESTPlus&lt;/code&gt; auto-generates from the class names you give to resources, and you can rename if you want - details of both of those bits of logic &lt;a href="https://flask-restplus.readthedocs.io/en/stable/swagger.html#documenting-the-methods"&gt;here&lt;/a&gt;. &lt;code&gt;pyswagger&lt;/code&gt; makes sure you pass in all the right arguments in the right format, so if you have models in the schema you pretty much have to use the API correctly or any attempts will be rejected, which is great for catching bugs early.&lt;/p&gt;
&lt;h2 id="result"&gt;Result&lt;/h2&gt;
&lt;p&gt;Here&amp;rsquo;s the project - &lt;a href="https://github.com/olipratt/microcarddeck"&gt;microcarddeck&lt;/a&gt;. I didn&amp;rsquo;t end up implementing much function because I didn&amp;rsquo;t need to - I got to exercise the &lt;code&gt;pyswagger&lt;/code&gt; package and get a feel for how to use it, and got a good simple bit of reference code to crib from in the future.&lt;/p&gt;</content><category term="Python"></category><category term="REST"></category><category term="Swagger"></category><category term="pyswagger"></category><category term="microservice"></category></entry><entry><title>The C++ Short String Optimisation</title><link href="http://olipratt.co.uk/the-cpp-short-string-optimisation.html" rel="alternate"></link><published>2016-11-19T12:28:00+00:00</published><updated>2016-11-19T12:28:00+00:00</updated><author><name>Oli Pratt</name></author><id>tag:olipratt.co.uk,2016-11-19:/the-cpp-short-string-optimisation.html</id><summary type="html">&lt;p&gt;While learning and reading up on C++11 recently, I came across the Short String Optimisation.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d at some point been told (or somehow got it into my head), that C &lt;code&gt;union&lt;/code&gt;s are generally dangerous and are something you should steer well clear of, so I&amp;rsquo;d never really known what they were about. However, from learning about the SSO it&amp;rsquo;s clear they can make for some very efficient memory use as â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;While learning and reading up on C++11 recently, I came across the Short String Optimisation.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d at some point been told (or somehow got it into my head), that C &lt;code&gt;union&lt;/code&gt;s are generally dangerous and are something you should steer well clear of, so I&amp;rsquo;d never really known what they were about. However, from learning about the SSO it&amp;rsquo;s clear they can make for some very efficient memory use as long as you are careful. (If you&amp;rsquo;re familiar with &lt;code&gt;union&lt;/code&gt;s this whole thing will probably be underwhelming!).&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll attempt an explanation here in my own words so I can make sure I understand the topic.&lt;/p&gt;
&lt;h2 id="deriving-the-sso"&gt;Deriving the SSO&lt;/h2&gt;
&lt;h3 id="baby-steps"&gt;Baby Steps&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s try and implement a C++ &lt;code&gt;string&lt;/code&gt; class, and be as memory and processor efficient as we can. Assuming a 64-bit system, we&amp;rsquo;ll need at least:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;code&gt;char *string&lt;/code&gt; pointer to the string - the string itself will have to be on the heap somewhere as it can be arbitrarily large,&lt;/li&gt;
&lt;li&gt;A &lt;code&gt;uint64_t length&lt;/code&gt; - again allowing for arbitrary largeness.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That&amp;rsquo;s pretty good so far, only 16 bytes used and we can manage arbitrarily large strings.&lt;/p&gt;
&lt;h3 id="minimising-reallocation"&gt;Minimising Reallocation&lt;/h3&gt;
&lt;p&gt;Now imagine we&amp;rsquo;re working with a string, and appending &lt;code&gt;char&lt;/code&gt;s to it to build some bigger string, one-by-one. That means each time one is appended, we have to &lt;code&gt;realloc&lt;/code&gt; our string, which may well mean a &lt;code&gt;malloc&lt;/code&gt; of new memory, a &lt;code&gt;memcpy&lt;/code&gt; of the whole string, and a &lt;code&gt;free&lt;/code&gt; of the old string. That&amp;rsquo;s far from ideal, so lets add one more field:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;code&gt;uint64_t allocated_length&lt;/code&gt; - this will separately store the size of any allocated memory, meaning we can, for example, double the amount of memory allocated when we run out, to achieve &lt;a href="https://en.wikipedia.org/wiki/Dynamic_array#Geometric_expansion_and_amortized_cost"&gt;amortised constant time cost&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cool, we&amp;rsquo;re up to 24 bytes now and can handle large strings pretty optimally.&lt;/p&gt;
&lt;h3 id="wasnt-this-about-short-strings"&gt;Wasn&amp;rsquo;t This About Short Strings?&lt;/h3&gt;
&lt;p&gt;What about small strings though? If I create only a little string &lt;code&gt;Hello world!&lt;/code&gt;, I have to allocate some memory on the heap to hold it. Going further, say I create an array of several two character strings, every single one has to separately allocate and later free memory. That&amp;rsquo;s not great, so lets try and improve it.&lt;/p&gt;
&lt;p&gt;We could add a small array to our string class that we use for small strings - say something like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;code&gt;char short_string[16]&lt;/code&gt; - any 16 byte or shorter string gets put in here.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But then, every string class instance gets 16 bytes bigger, whether it needs it or not, and the space is completely useless for long strings (unless we split them across this array and any allocated memory, but then the string&amp;rsquo;s not contiguous in memory and that&amp;rsquo;s going to make it useless to any number of standard functions that expect that).&lt;/p&gt;
&lt;p&gt;So let&amp;rsquo;s not do that - but notice if we did, when the array was in use the &lt;code&gt;char *string&lt;/code&gt; and &lt;code&gt;uint64_t allocated_length&lt;/code&gt; would be useless, and they would be wasted instead&amp;hellip;&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s where the &lt;code&gt;union&lt;/code&gt; steps in - lets define our string class&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt; as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;string&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;uint64_t&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;  &lt;span class="c1"&gt;// The real string length.&lt;/span&gt;
  &lt;span class="k"&gt;union&lt;/span&gt;  &lt;span class="c1"&gt;// One of...&lt;/span&gt;
  &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;struct&lt;/span&gt;  &lt;span class="c1"&gt;// ...a string on the heap and the memory size if needed...&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
      &lt;span class="kt"&gt;uint64_t&lt;/span&gt; &lt;span class="n"&gt;allocated_length&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="n"&gt;long_string&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="n"&gt;short_string&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;long_string&lt;/span&gt;&lt;span class="p"&gt;)];&lt;/span&gt;  &lt;span class="c1"&gt;// ...or a small array.&lt;/span&gt;
  &lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That&amp;rsquo;s a common 8 byte length of the actual string, and then an either-or of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pointer-to-string and allocated length&lt;/li&gt;
&lt;li&gt;&lt;code&gt;char&lt;/code&gt; array of the same size as the above takes up - 16 bytes here.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now if our string is 16 characters or shorter, we can pack it directly into the memory of the string class itself, and if it&amp;rsquo;s longer, we treat the union as a pointer and length and store the string there instead!&lt;/p&gt;
&lt;h3 id="but-wait-theres-more"&gt;But Wait, There&amp;rsquo;s More&lt;/h3&gt;
&lt;p&gt;In the case above that we&amp;rsquo;re using the short string buffer, the largest length we need to store is going to be 15 (assuming the string is stored null-terminated), so the &lt;code&gt;uint64_t&lt;/code&gt; is overkill. Let&amp;rsquo;s try turning the whole thing into one big &lt;code&gt;union&lt;/code&gt;, using only a single byte to store the length in the short case:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;string&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;union&lt;/span&gt;
  &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;struct&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="kt"&gt;uint64_t&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
      &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
      &lt;span class="kt"&gt;uint64_t&lt;/span&gt; &lt;span class="n"&gt;allocated_length&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="n"&gt;long_string&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;struct&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="kt"&gt;uint8_t&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
      &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;long_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="n"&gt;short_string&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Great, now our short string can be 23 bytes long, but there&amp;rsquo;s one problem - how do we know which type to treat the &lt;code&gt;union&lt;/code&gt; as when using this class?&lt;/p&gt;
&lt;p&gt;To solve this, we can take advantage of the fact that in the short case we need only about 5 bits to store the length, and  &lt;em&gt;surely&lt;/em&gt; no-one will mind if we limit them to a paltry &lt;code&gt;2^63&lt;/code&gt;&lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt; byte string, so lets steal the high bit&lt;sup id="fnref-3"&gt;&lt;a class="footnote-ref" href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt; from the length to act as a flag for whether we&amp;rsquo;re treating the union one way or the other.&lt;/p&gt;
&lt;h3 id="squeezing-out-the-last-drops"&gt;Squeezing Out the Last Drops&lt;/h3&gt;
&lt;p&gt;There&amp;rsquo;s one final thing we can tweak to do better. As it stands, swapping back and forth from a 23 byte to a 24 byte string means allocating a string and copying into it one way, and then copying back and freeing it the other. Instead once we allocate a string and set the bit flag, we can just never unset it - so when a string shrinks to 23 bytes or less, we just continue using the allocated space.&lt;/p&gt;
&lt;p&gt;And that&amp;rsquo;s how we can use just 24 bytes of space to point to arbitrarily long strings &lt;em&gt;and&lt;/em&gt; still store 23 byte strings without having to allocate any extra memory!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;I&amp;rsquo;m not claiming that any real implementations look exactly like any of the ones in this post - but it gives an illustrative idea. &lt;a href="https://github.com/elliotgoodrich/SSO-23"&gt;Here&amp;rsquo;s a real implementation, with some good explanatory diagrams&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;Even modern 64 bit CPUs can&amp;rsquo;t actually address the full 64 bit space - the current limit is about &lt;a href="http://www.howtogeek.com/175443/what-is-the-maximum-amount-of-ram-you-could-theoretically-put-in-a-64-bit-computer/"&gt;46 bits&lt;/a&gt; - so this isn&amp;rsquo;t even a real limitation as it stands. (A limit that HP&amp;rsquo;s search-engine-unagreeably-named &amp;ldquo;The Machine&amp;rdquo; is coming up against!)&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-3"&gt;
&lt;p&gt;Yes, I&amp;rsquo;m ignoring endianness for the purposes of this post.&amp;#160;&lt;a class="footnote-backref" href="#fnref-3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="C++"></category><category term="optimisation"></category><category term="performance"></category></entry><entry><title>Python REST API With SwaggerUI</title><link href="http://olipratt.co.uk/python-rest-api-with-swaggerui.html" rel="alternate"></link><published>2016-10-29T11:45:00+01:00</published><updated>2016-10-29T11:45:00+01:00</updated><author><name>Oli Pratt</name></author><id>tag:olipratt.co.uk,2016-10-29:/python-rest-api-with-swaggerui.html</id><summary type="html">&lt;p&gt;What with REST APIs and the &lt;a href="http://swagger.io/"&gt;swagger&lt;/a&gt; framework for documenting and integrating them being the in-thing lately, to start getting to grips with them I wanted to see how easy it would be to create a simple one in Python with minimal code from me. Turns out it was very simple.&lt;/p&gt;
&lt;p&gt;As practice project I picked writing a really simple datastore.&lt;/p&gt;
&lt;h2 id="choosing-a-package"&gt;Choosing a Package&lt;/h2&gt;
&lt;p&gt;After looking around for something that provides a SwaggerUI (&lt;a href="http://petstore.swagger.io/"&gt;demo here â€¦&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;What with REST APIs and the &lt;a href="http://swagger.io/"&gt;swagger&lt;/a&gt; framework for documenting and integrating them being the in-thing lately, to start getting to grips with them I wanted to see how easy it would be to create a simple one in Python with minimal code from me. Turns out it was very simple.&lt;/p&gt;
&lt;p&gt;As practice project I picked writing a really simple datastore.&lt;/p&gt;
&lt;h2 id="choosing-a-package"&gt;Choosing a Package&lt;/h2&gt;
&lt;p&gt;After looking around for something that provides a SwaggerUI (&lt;a href="http://petstore.swagger.io/"&gt;demo here&lt;/a&gt; to see what this looks like) and schema, I found &lt;a href="https://flask-restplus.readthedocs.io/en/stable/index.html"&gt;Flask-RESTPlus&lt;/a&gt; which does this &lt;a href="https://flask-restplus.readthedocs.io/en/stable/swagger.html#swagger-ui"&gt;really easily out of the box&lt;/a&gt;. It also builds on top of &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; which I&amp;rsquo;ve heard good things about and wanted to try for a while - having only used &lt;a href="http://cherrypy.org/"&gt;cherrypy&lt;/a&gt; before myself.&lt;/p&gt;
&lt;p&gt;Another thing I wanted was to be able to easily test the API, and it seemed  &lt;code&gt;Flask&lt;/code&gt; is really &lt;a href="http://flask.pocoo.org/docs/0.11/testing/"&gt;easy to test&lt;/a&gt;, and so by extension so is &lt;code&gt;Flask-RESTPlus&lt;/code&gt; as it just plugs in on top. So this combo sounded like a good choice to get going.&lt;/p&gt;
&lt;p&gt;I also needed some way to store the data and so looked for a really simple key-value store. A quick search gave &lt;a href="http://tinydb.readthedocs.io/en/latest/getting-started.html"&gt;TinyDB&lt;/a&gt; - small, easy to set up, and stores Python &lt;code&gt;dict&lt;/code&gt;s directly (&lt;a href="https://docs.python.org/3.5/library/json.html#json.loads"&gt;easily converted to&lt;/a&gt; from the JSON used in the API).&lt;/p&gt;
&lt;h2 id="getting-started"&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;Getting something up and running was very straightforward - I followed the tutorial &lt;a href="http://michal.karzynski.pl/blog/2016/06/19/building-beautiful-restful-apis-using-flask-swagger-ui-flask-restplus/"&gt;here&lt;/a&gt; and wrote tests as I went.&lt;/p&gt;
&lt;p&gt;That was followed by lots of tweaking/playing with the contents of the SwaggerUI page and working out how to create data models to enforce on the API, but the bulk of the work to get going was trivial.&lt;/p&gt;
&lt;h2 id="impressions"&gt;Impressions&lt;/h2&gt;
&lt;p&gt;The SwaggerUI page is &lt;strong&gt;really&lt;/strong&gt; great for exploring and documenting APIs. Often it&amp;rsquo;s hard to grasp how to integrate with some new code from reading it, but here you can actually play with the interface, press buttons to see what happens, and provide input and follow it through different API calls - really nice to use. Definitely like it and plan to use it more.&lt;/p&gt;
&lt;p&gt;With a bit of reading of the &lt;code&gt;Flask-RESTPlus&lt;/code&gt; docs you can edit all the fields and documentation in the Swagger UI page so you can make it as easy to use as possible - looks like it&amp;rsquo;s fully featured in that respect and was a good choice.&lt;/p&gt;
&lt;h2 id="gotchas"&gt;Gotchas&lt;/h2&gt;
&lt;p&gt;It wasn&amp;rsquo;t entirely plain sailing though - here are the main problems I hit that it&amp;rsquo;s worth being aware of!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You have to use a non-empty prefix for your API to start at (&lt;a href="https://flask-restplus.readthedocs.io/en/stable/api.html#flask_restplus.Api"&gt;&lt;code&gt;prefix&lt;/code&gt; parameter here&lt;/a&gt;). I &lt;a href="https://github.com/noirbizarre/flask-restplus/issues/210"&gt;raised an issue about it&lt;/a&gt; but it didn&amp;rsquo;t garner much attention. It&amp;rsquo;s pretty minor though - I suspect any real system would not have the API exposed on &lt;code&gt;/&lt;/code&gt; directly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It doesn&amp;rsquo;t seem like the swagger schema is exposed anywhere over HTTP by &lt;code&gt;Flask-RESTPlus&lt;/code&gt; by default. However, it&amp;rsquo;s really easy to do so, just return &lt;code&gt;api.__schema__&lt;/code&gt; as the response to a &lt;code&gt;GET&lt;/code&gt; request and it&amp;rsquo;s there. I ended up doing that in a separate &lt;code&gt;schema&lt;/code&gt; namespace so it gets it&amp;rsquo;s own top-level section in the SwaggerUI.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you use the &lt;code&gt;@api.expect&lt;/code&gt; decorator to state what model the incoming data must match, &lt;code&gt;Flask-RESTPlus&lt;/code&gt; won&amp;rsquo;t force incoming data to conform unless you set the &lt;code&gt;validate=True&lt;/code&gt; parameter on it - seems like the wrong default to me&amp;hellip;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="end-result"&gt;End Result&lt;/h2&gt;
&lt;p&gt;And here&amp;rsquo;s the result - &lt;a href="https://github.com/olipratt/microstore"&gt;microstore&lt;/a&gt; - a trivial datastore with a rest API and documented and interactive via SwaggerUI. I kept all the code &lt;a href="https://github.com/olipratt/microstore/blob/master/microstore.py"&gt;in one file&lt;/a&gt; to make it as simple a reference as possible.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d say it was a success, and was a fun weekend!&lt;/p&gt;</content><category term="Python"></category><category term="REST"></category><category term="Swagger"></category><category term="Flask-RESTPlus"></category><category term="microservice"></category></entry></feed>